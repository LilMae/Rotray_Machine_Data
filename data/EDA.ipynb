{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import io\n",
    "from tqdm import tqdm\n",
    "\n",
    "data_root = os.path.join(os.getcwd(), 'dataset')\n",
    "new_data_root = os.path.join(os.getcwd(), 'new_dataset')\n",
    "if os.path.isdir(new_data_root):\n",
    "    shutil.rmtree(new_data_root)\n",
    "os.mkdir(new_data_root)\n",
    "\n",
    "header = ['motor_x', 'motor_y', 'disk_x', 'disk_y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 저장 규칙\n",
    "1. {class_name}{rpm}{cnt}{severity}.csv 로 한다  \n",
    "`{class_name}_{sampling_rate_str}_{rpm}_{severity}_{load_condition}_{cnt}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. FaultDXAI\n",
    "paper name : `Fault Diagnosis using eXplainable AI: A transfer learning-based approach for rotating machinery exploiting augmented synthetic data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for Test 09_Normal Condition : 420 files exist\n",
      "for Test 06_Normal Condition : 420 files exist\n",
      "for Test 03_Normal Condition : 420 files exist\n",
      "for Test 18_Unbalance : 420 files exist\n",
      "for Test 20_Unbalance : 420 files exist\n",
      "for Test 15_Unbalance : 420 files exist\n",
      "for Test 17_Normal Condition : 420 files exist\n",
      "for Test 08_Looseness : 420 files exist\n",
      "for Test 13_Misalignment : 420 files exist\n",
      "for Test 07_Unbalance : 420 files exist\n",
      "for Test 05_Looseness : 420 files exist\n",
      "for Test 19_Looseness : 420 files exist\n",
      "for Test 11_Misalignment : 420 files exist\n",
      "for Test 16_Misalignment : 420 files exist\n",
      "for Test 14_Looseness : 420 files exist\n",
      "for Test 12_Looseness : 420 files exist\n",
      "for Test 02_Misalignment : 420 files exist\n",
      "for Test 04_Unbalance : 420 files exist\n",
      "for Test 10_Misalignment : 420 files exist\n",
      "for Test 01_Normal Condition : 420 files exist\n"
     ]
    }
   ],
   "source": [
    "def dxai(data_root, new_data_root):\n",
    "    dxai_root = os.path.join(data_root, '1_FaultDXAI')\n",
    "\n",
    "    rpm = 1238\n",
    "    sampling_rate_str = '25kHz'\n",
    "    load_condition = 'unknwon'\n",
    "    severity = 'none'\n",
    "\n",
    "    new_dxai_root = os.path.join(new_data_root, 'dxai')\n",
    "    if os.path.isdir(new_dxai_root):\n",
    "        shutil.rmtree(new_dxai_root)\n",
    "    os.mkdir(new_dxai_root)\n",
    "\n",
    "    for test_name in os.listdir(dxai_root):\n",
    "        test_folder = os.path.join(dxai_root, test_name, test_name)\n",
    "        \n",
    "        class_name = test_name.split('_')[-1].split(' ')[0].lower()\n",
    "        test_folder_dist = os.path.join(new_dxai_root, class_name)\n",
    "        if not os.path.exists(test_folder_dist):\n",
    "            os.mkdir(test_folder_dist)\n",
    "        \n",
    "        print(f'for {test_name} : {len(os.listdir(test_folder))} files exist')\n",
    "        for test_file in os.listdir(test_folder):\n",
    "            file_path = os.path.join(test_folder, test_file)\n",
    "            file_np = np.load(file_path)\n",
    "            motor_y = file_np[0]\n",
    "            motor_x = file_np[1]\n",
    "            disk_y = file_np[2]\n",
    "            disk_x = file_np[3]\n",
    "            \n",
    "            data_pd = pd.DataFrame({'motor_x' : motor_x, \n",
    "                                    'motor_y' : motor_y, \n",
    "                                    'disk_x' : disk_x, \n",
    "                                    'disk_y' : disk_y})\n",
    "            data_pd.to_csv(os.path.join(test_folder_dist, f'{class_name}_{sampling_rate_str}_{rpm}_{severity}_{load_condition}_{len(os.listdir(test_folder_dist))+1}.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. IIS \n",
    "paper name : `Machine Learning-Based Unbalance Detection of a Rotating Shaft Using Vibration Data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : unbalance with 60.7mm g\n",
      "number of speed : 3322, total : 3323 slice exist\n",
      "Processing : unbalance with 75.5mm g\n",
      "number of speed : 3364, total : 3365 slice exist\n",
      "Processing : unbalance with 75.5mm g\n",
      "number of speed : 12878, total : 12879 slice exist\n",
      "Processing : unbalance with 152.1mm g\n",
      "number of speed : 3370, total : 3371 slice exist\n",
      "Processing : unbalance with 45.9mm g\n",
      "number of speed : 3368, total : 3369 slice exist\n",
      "Processing : unbalance with 60.7mm g\n",
      "number of speed : 12888, total : 12889 slice exist\n",
      "Processing : normal with 0.0mm g\n",
      "number of speed : 3358, total : 3359 slice exist\n",
      "Processing : unbalance with 45.9mm g\n",
      "number of speed : 12888, total : 12889 slice exist\n",
      "Processing : unbalance with 152.1mm g\n",
      "number of speed : 12880, total : 12881 slice exist\n",
      "Processing : normal with 0.0mm g\n",
      "number of speed : 12894, total : 12895 slice exist\n"
     ]
    }
   ],
   "source": [
    "def iis(data_root, new_data_root):\n",
    "\n",
    "    iis_root = os.path.join(data_root, '2_IIS')\n",
    "\n",
    "    # Parameters\n",
    "    sampling_rate = 4096  # 4096 samples per second\n",
    "    samplint_rate_str = '4096Hz'\n",
    "    window_size = 1.0  # 1 second\n",
    "    stride = 0.5  # 0.5 second\n",
    "    load_condition = 'unknwon'\n",
    "\n",
    "    new_iss_root = os.path.join(new_data_root, 'iis')\n",
    "    if os.path.isdir(new_iss_root):\n",
    "        shutil.rmtree(new_iss_root)\n",
    "    os.mkdir(new_iss_root)\n",
    "\n",
    "    for test_path in glob.glob(os.path.join(iis_root,'*.csv')):\n",
    "        \n",
    "        test_name = os.path.split(test_path)[-1]\n",
    "        if int(test_name[0]) == 0:\n",
    "            class_name = 'normal'\n",
    "            severity = 0\n",
    "        else:\n",
    "            class_name = 'unbalance'\n",
    "            severity = [0, 459, 607, 755, 1521]\n",
    "            severity = severity[int(test_name[0])]\n",
    "        \n",
    "        test_folder_dist = os.path.join(new_iss_root, class_name)\n",
    "        if not os.path.exists(test_folder_dist):\n",
    "            os.mkdir(test_folder_dist)\n",
    "        \n",
    "        print(f'Processing : {class_name} with {severity/10}mm g')\n",
    "        \n",
    "        start = 0\n",
    "        data_sec = 0.0\n",
    "        cnt = 0\n",
    "        is_first_segment = True  # Flag to skip the first segment\n",
    "        \n",
    "        exp_pd = pd.read_csv(test_path)\n",
    "        \n",
    "        speed_df = exp_pd['Measured_RPM']\n",
    "        \n",
    "        change_indices = [0]  # Start with the first index\n",
    "        change_indices += speed_df.index[\n",
    "            (speed_df.diff().abs() > 10)\n",
    "        ].tolist()\n",
    "        \n",
    "        for change_index in change_indices[1:]:\n",
    "            end = change_index\n",
    "            \n",
    "            static_speed = exp_pd.iloc()[start:end]\n",
    "            \n",
    "            disk_x = static_speed['Vibration_1']\n",
    "            disk_y = static_speed['Vibration_2']\n",
    "            motor_y = static_speed['Vibration_3']\n",
    "            \n",
    "            data_pd = pd.DataFrame({'motor_x' : None, \n",
    "                                    'motor_y' : motor_y, \n",
    "                                    'disk_x' : disk_x, \n",
    "                                    'disk_y' : disk_y})\n",
    "            \n",
    "            mean_rpm = int(static_speed['Measured_RPM'].mean())\n",
    "            \n",
    "            cnt += 1\n",
    "            start = end\n",
    "            \n",
    "            # Skip the first segment\n",
    "            if is_first_segment:\n",
    "                is_first_segment = False\n",
    "                continue\n",
    "            \n",
    "            # Slice data_pd by 1-second window with 0.5-second stride\n",
    "            window_samples = int(window_size * sampling_rate)\n",
    "            stride_samples = int(stride * sampling_rate)\n",
    "            num_rows = len(data_pd)\n",
    "            \n",
    "            for slice_start in range(0, num_rows - window_samples + 1, stride_samples):\n",
    "                slice_end = slice_start + window_samples\n",
    "                sliced_data = data_pd.iloc[slice_start:slice_end]\n",
    "                \n",
    "                cnt += 1\n",
    "                \n",
    "                # Save sliced data to a CSV file\n",
    "                output_file = os.path.join(test_folder_dist, f'{class_name}_{sampling_rate_str}_{mean_rpm}_{severity/10}mmg_{load_condition}_{cnt}.csv')\n",
    "                sliced_data.to_csv(output_file, index=False)\n",
    "            \n",
    "\n",
    "        print(f'number of speed : {cnt-1}, total : {cnt} slice exist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. VAT-MCD\n",
    "paper name : `Vibration, acoustic, temperature, and motor current dataset of rotating machine under varying operating conditions for fault diagnosis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_condition : 2Nm, class_name : misalign, severity : 03\n",
      "num data slices : 239\n",
      "load_condition : 4Nm, class_name : normal, severity : normal\n",
      "num data slices : 239\n",
      "load_condition : 0Nm, class_name : misalign, severity : 03\n",
      "num data slices : 239\n",
      "load_condition : 0Nm, class_name : bpfi, severity : 10\n",
      "num data slices : 119\n",
      "load_condition : 4Nm, class_name : misalign, severity : 03\n",
      "num data slices : 239\n",
      "load_condition : 4Nm, class_name : unbalance, severity : 0583mg\n",
      "num data slices : 239\n",
      "load_condition : 2Nm, class_name : misalign, severity : 01\n",
      "num data slices : 239\n",
      "load_condition : 4Nm, class_name : bpfo, severity : 30\n",
      "num data slices : 119\n",
      "load_condition : 2Nm, class_name : bpfi, severity : 10\n",
      "num data slices : 119\n",
      "load_condition : 0Nm, class_name : unbalance, severity : 1169mg\n",
      "num data slices : 239\n",
      "load_condition : 0Nm, class_name : misalign, severity : 05\n",
      "num data slices : 239\n",
      "load_condition : 2Nm, class_name : normal, severity : normal\n",
      "num data slices : 239\n",
      "load_condition : 0Nm, class_name : bpfi, severity : 03\n",
      "num data slices : 119\n",
      "load_condition : 2Nm, class_name : unbalance, severity : 1751mg\n",
      "num data slices : 239\n",
      "load_condition : 2Nm, class_name : misalign, severity : 05\n",
      "num data slices : 239\n",
      "load_condition : 0Nm, class_name : unbalance, severity : 2239mg\n",
      "num data slices : 239\n",
      "load_condition : 4Nm, class_name : unbalance, severity : 2239mg\n",
      "num data slices : 239\n",
      "load_condition : 2Nm, class_name : bpfo, severity : 03\n",
      "num data slices : 119\n",
      "load_condition : 2Nm, class_name : bpfi, severity : 30\n",
      "num data slices : 119\n",
      "load_condition : 0Nm, class_name : unbalance, severity : 3318mg\n",
      "num data slices : 239\n",
      "load_condition : 2Nm, class_name : bpfi, severity : 03\n",
      "num data slices : 119\n",
      "load_condition : 4Nm, class_name : bpfo, severity : 10\n",
      "num data slices : 119\n",
      "load_condition : 0Nm, class_name : misalign, severity : 01\n",
      "num data slices : 239\n",
      "load_condition : 2Nm, class_name : unbalance, severity : 3318mg\n",
      "num data slices : 239\n",
      "load_condition : 0Nm, class_name : normal, severity : normal\n",
      "num data slices : 599\n",
      "load_condition : 4Nm, class_name : bpfi, severity : 10\n",
      "num data slices : 119\n",
      "load_condition : 0Nm, class_name : bpfo, severity : 10\n",
      "num data slices : 119\n",
      "load_condition : 0Nm, class_name : bpfo, severity : 03\n",
      "num data slices : 119\n",
      "load_condition : 2Nm, class_name : unbalance, severity : 2239mg\n",
      "num data slices : 239\n",
      "load_condition : 4Nm, class_name : unbalance, severity : 3318mg\n",
      "num data slices : 239\n",
      "load_condition : 4Nm, class_name : misalign, severity : 01\n",
      "num data slices : 239\n",
      "load_condition : 4Nm, class_name : bpfi, severity : 30\n",
      "num data slices : 119\n",
      "load_condition : 4Nm, class_name : misalign, severity : 05\n",
      "num data slices : 239\n",
      "load_condition : 4Nm, class_name : bpfi, severity : 03\n",
      "num data slices : 119\n",
      "load_condition : 2Nm, class_name : unbalance, severity : 1169mg\n",
      "num data slices : 239\n",
      "load_condition : 0Nm, class_name : unbalance, severity : 1751mg\n",
      "num data slices : 239\n",
      "load_condition : 2Nm, class_name : unbalance, severity : 0583mg\n",
      "num data slices : 239\n",
      "load_condition : 4Nm, class_name : unbalance, severity : 1169mg\n",
      "num data slices : 239\n",
      "load_condition : 0Nm, class_name : bpfo, severity : 30\n",
      "num data slices : 119\n",
      "load_condition : 4Nm, class_name : unbalance, severity : 1751mg\n",
      "num data slices : 239\n",
      "load_condition : 0Nm, class_name : bpfi, severity : 30\n",
      "num data slices : 119\n",
      "load_condition : 0Nm, class_name : unbalance, severity : 0583mg\n",
      "num data slices : 239\n",
      "load_condition : 2Nm, class_name : bpfo, severity : 10\n",
      "num data slices : 119\n",
      "load_condition : 4Nm, class_name : bpfo, severity : 03\n",
      "num data slices : 119\n",
      "load_condition : 2Nm, class_name : bpfo, severity : 30\n",
      "num data slices : 119\n"
     ]
    }
   ],
   "source": [
    "def vat(data_root, new_data_root):\n",
    "    vat_root = os.path.join(data_root, '3_VAT_mat')\n",
    "\n",
    "    sampling_rate = 25600 # 25.6kHz\n",
    "    sampling_rate_str = '25.6kHz'\n",
    "    window_size = 1.0  # 1 second\n",
    "    stride = 0.5  # 0.5 second\n",
    "    rpm = 3010\n",
    "\n",
    "    new_vat_root = os.path.join(new_data_root, 'vat')\n",
    "    if os.path.isdir(new_vat_root):\n",
    "        shutil.rmtree(new_vat_root)\n",
    "    os.mkdir(new_vat_root)\n",
    "\n",
    "    for file_name in os.listdir(vat_root):\n",
    "        \n",
    "        load_condition = file_name.split('.')[0].split('_')[0]\n",
    "        class_name = file_name.split('.')[0].split('_')[1].lower()\n",
    "        if class_name != 'normal':\n",
    "            severity = file_name.split('.')[0].split('_')[2]\n",
    "        else:\n",
    "            severity = 'normal'\n",
    "        if class_name == 'unbalalnce':\n",
    "            class_name = 'unbalance'\n",
    "        \n",
    "        print(f'load_condition : {load_condition}, class_name : {class_name}, severity : {severity}')\n",
    "        \n",
    "        test_folder_dist = os.path.join(new_vat_root, class_name)\n",
    "        if not os.path.exists(test_folder_dist):\n",
    "            os.mkdir(test_folder_dist)\n",
    "        \n",
    "        file_path = os.path.join(vat_root, file_name)\n",
    "        \n",
    "        mat_file = io.loadmat(file_path)\n",
    "        signal = mat_file['Signal'][0][0][1][0][0][0]\n",
    "        data_pd = pd.DataFrame(signal, columns=['motor_x','motor_y','disk_x','disk_y'])\n",
    "        \n",
    "        # Slice data_pd by 1-second window with 0.5-second stride\n",
    "        window_samples = int(window_size * sampling_rate)\n",
    "        stride_samples = int(stride * sampling_rate)\n",
    "        num_rows = len(data_pd)\n",
    "        \n",
    "        cnt = 0\n",
    "        for slice_start in range(0, num_rows - window_samples + 1, stride_samples):\n",
    "            slice_end = slice_start + window_samples\n",
    "            sliced_data = data_pd.iloc[slice_start:slice_end]\n",
    "            \n",
    "            cnt += 1\n",
    "            \n",
    "            # Save sliced data to a CSV file\n",
    "            output_file = os.path.join(test_folder_dist, f'{class_name}_{sampling_rate_str}_{rpm}_{severity}_{load_condition}_{cnt}.csv')\n",
    "            sliced_data.to_csv(output_file, index=False)\n",
    "        \n",
    "        print(f'num data slices : {cnt}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. VBL-VA001\n",
    "\n",
    "paper_name : `Lab-Scale Vibration Analysis Dataset and Baseline Methods for Machinery Fault Diagnosis with Machine Learning`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [03:51<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num data slices : 8000\n",
      "Processing : misalignment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [03:53<00:00,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num data slices : 8000\n",
      "Processing : bearing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [03:57<00:00,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num data slices : 8000\n",
      "Processing : unbalance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [03:53<00:00,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num data slices : 8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def vbl(data_root, new_data_root):\n",
    "\n",
    "    vbl_root = os.path.join(data_root, '4_VBL-VA001')\n",
    "\n",
    "    sampling_rate = 20000 # 20kHz\n",
    "    sampling_rate_str = '20kHz'\n",
    "    window_size = 1.0  # 1 second\n",
    "    stride = 0.5  # 0.5 second\n",
    "    rpm = 3000\n",
    "    load_condition = 'unknown'\n",
    "\n",
    "    new_vbl_root = os.path.join(new_data_root, 'vbl')\n",
    "    if os.path.isdir(new_vbl_root):\n",
    "        shutil.rmtree(new_vbl_root)\n",
    "    os.mkdir(new_vbl_root)\n",
    "\n",
    "\n",
    "    for class_name in os.listdir(vbl_root):\n",
    "        class_folder = os.path.join(vbl_root, class_name)\n",
    "        \n",
    "        test_folder_dist = os.path.join(new_vbl_root, class_name)\n",
    "        if not os.path.exists(test_folder_dist):\n",
    "            os.mkdir(test_folder_dist)\n",
    "        \n",
    "        print(f'Processing : {class_name}')\n",
    "        cnt = 0\n",
    "        for file_name in tqdm(os.listdir(class_folder)):\n",
    "            file_path = os.path.join(class_folder, file_name)\n",
    "            data_pd = pd.read_csv(file_path, header=None)\n",
    "            data_pd.columns = ['time', 'motor_x', 'motor_y', 'motor_z']\n",
    "            data_pd = data_pd.drop(labels='time', axis=1)\n",
    "            \n",
    "            if class_name == 'unbalance':\n",
    "                severity = file_name.split('_')[1]\n",
    "                \n",
    "                if severity == 'z':\n",
    "                    severity = file_name.split('_')[0][-2:]\n",
    "            else:\n",
    "                severity = 'none'\n",
    "            \n",
    "            # Slice data_pd by 1-second window with 0.5-second stride\n",
    "            window_samples = int(window_size * sampling_rate)\n",
    "            stride_samples = int(stride * sampling_rate)\n",
    "            num_rows = len(data_pd)\n",
    "            \n",
    "            \n",
    "            for slice_start in range(0, num_rows - window_samples + 1, stride_samples):\n",
    "                slice_end = slice_start + window_samples\n",
    "                sliced_data = data_pd.iloc[slice_start:slice_end]\n",
    "                \n",
    "                cnt += 1\n",
    "                \n",
    "                # Save sliced data to a CSV file\n",
    "                output_file = os.path.join(test_folder_dist, f'{class_name}_{sampling_rate_str}_{rpm}_{severity}_{load_condition}_{cnt}.csv')\n",
    "                sliced_data.to_csv(output_file, index=False)\n",
    "            \n",
    "        print(f'num data slices : {cnt}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. MaFaulDa\n",
    "paper name : `None`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfd_file_read_save(data_pd, folder_dist , class_name, severity):\n",
    "    sampling_rate_str = '50kHz'\n",
    "    \n",
    "    load_condition = 'unknown'\n",
    "    # Hyper Params\n",
    "    sampling_rate = 50000\n",
    "    mfd_columns = ['tachometer', 'motor_z', 'motor_y', 'motor_x', 'disk_z', 'disk_y', 'disk_x', 'microphone']\n",
    "    window_size = 1.0  # 1 second\n",
    "    stride = 0.5  # 0.5 second\n",
    "    \n",
    "    if not os.path.exists(folder_dist):\n",
    "        os.mkdir(folder_dist)\n",
    "    \n",
    "    data_pd.columns = mfd_columns\n",
    "\n",
    "    tachometer_np = data_pd['tachometer'].to_numpy()\n",
    "    tachometer_np = np.convolve(tachometer_np, np.ones(5) / 5, mode='same')\n",
    "    binary_np = (tachometer_np >3).astype(int)\n",
    "    rising_edges = np.where(np.diff(binary_np) > 0)[0]\n",
    "    pulse_intervals = np.diff(rising_edges) / sampling_rate \n",
    "\n",
    "    avg_time_per_revolution = np.mean(pulse_intervals)\n",
    "\n",
    "    rpm = int((1 / avg_time_per_revolution) * 60)\n",
    "\n",
    "\n",
    "    # Slice data_pd by 1-second window with 0.5-second stride\n",
    "    window_samples = int(window_size * sampling_rate)\n",
    "    stride_samples = int(stride * sampling_rate)\n",
    "    num_rows = len(data_pd)\n",
    "\n",
    "    for slice_start in range(0, num_rows - window_samples + 1, stride_samples):\n",
    "        slice_end = slice_start + window_samples\n",
    "        sliced_data = data_pd.iloc[slice_start:slice_end]\n",
    "        \n",
    "        \n",
    "        # Save sliced data to a CSV file\n",
    "        output_file = os.path.join(folder_dist, f'{class_name}_{sampling_rate_str}_{rpm}_{severity}_{load_condition}_{len(os.listdir(folder_dist))+1}.csv')\n",
    "        sliced_data.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : horizontal-misalignment\n",
      "Processing : horizontal-misalignment/1.0mm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [01:08<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : horizontal-misalignment/2.0mm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [01:08<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : horizontal-misalignment/0.5mm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:09<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : horizontal-misalignment/1.5mm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [01:08<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : vertical-misalignment\n",
      "Processing : vertical-misalignment/0.63mm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:09<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : vertical-misalignment/1.78mm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:09<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : vertical-misalignment/0.51mm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [01:11<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : vertical-misalignment/1.27mm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:10<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : vertical-misalignment/1.90mm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:10<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : vertical-misalignment/1.40mm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:10<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : imbalance\n",
      "Processing : imbalance/10g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [01:07<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : imbalance/20g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [01:08<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : imbalance/25g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [01:05<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : imbalance/6g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [01:09<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : imbalance/15g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [01:07<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : imbalance/35g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [01:02<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : imbalance/30g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [01:05<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : normal\n",
      "Processing : normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [01:09<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : underhang\n",
      "Processing : underhang/ball_fault/20g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [01:07<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : underhang/ball_fault/6g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [01:07<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : underhang/ball_fault/0g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:09<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : underhang/ball_fault/35g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:52<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : underhang/cage_fault/20g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [01:07<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : underhang/cage_fault/6g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [01:07<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : underhang/cage_fault/0g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [01:09<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : underhang/cage_fault/35g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:58<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : underhang/outer_race/20g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [01:08<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : underhang/outer_race/6g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [01:09<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : underhang/outer_race/0g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [01:09<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : underhang/outer_race/35g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [00:51<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : overhang\n",
      "Processing : overhang/ball_fault/20g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:33<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : overhang/ball_fault/6g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:58<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : overhang/ball_fault/0g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [01:06<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : overhang/ball_fault/35g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:27<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : overhang/cage_fault/20g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [01:07<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : overhang/cage_fault/6g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [01:09<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : overhang/cage_fault/0g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [01:10<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : overhang/cage_fault/35g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:56<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : overhang/outer_race/20g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [01:08<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : overhang/outer_race/6g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [01:09<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : overhang/outer_race/0g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [01:09<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : overhang/outer_race/35g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:57<00:00,  1.39s/it]\n"
     ]
    }
   ],
   "source": [
    "def mfd(data_root, new_data_root):\n",
    "\n",
    "    mfd_root = os.path.join(data_root, '6_MaFaulDa')\n",
    "\n",
    "    sampling_rate = 50000\n",
    "    window_size = 1.0\n",
    "    stride = 0.5\n",
    "\n",
    "    new_mfd_root = os.path.join(new_data_root, 'mfd')\n",
    "    if os.path.isdir(new_mfd_root):\n",
    "        shutil.rmtree(new_mfd_root)\n",
    "    os.mkdir(new_mfd_root)\n",
    "\n",
    "    for class_name in os.listdir(mfd_root):\n",
    "        \n",
    "        class_dir = os.path.join(mfd_root, class_name)\n",
    "        print(f'Processing : {class_name}')\n",
    "        if class_name in ['horizontal-misalignment', 'imbalance', 'vertical-misalignment']:\n",
    "            for severity in os.listdir(class_dir):\n",
    "                severity_dir = os.path.join(class_dir, severity)\n",
    "                print(f'Processing : {class_name}/{severity}')\n",
    "                for file_name in tqdm(os.listdir(severity_dir)):\n",
    "                    \n",
    "                    file_path = os.path.join(severity_dir, file_name)\n",
    "                    \n",
    "                    data_pd = pd.read_csv(file_path)\n",
    "                    \n",
    "                    dis_folder = os.path.join(new_mfd_root, class_name)\n",
    "\n",
    "                    mfd_file_read_save(data_pd, dis_folder, class_name, severity)\n",
    "                    \n",
    "                \n",
    "        elif class_name in ['overhang', 'underhang']:\n",
    "            for specific_class in os.listdir(class_dir):\n",
    "                specific_class_dir = os.path.join(class_dir, specific_class)\n",
    "                \n",
    "                for severity in os.listdir(specific_class_dir):\n",
    "                    severity_dir = os.path.join(specific_class_dir, severity)\n",
    "                    print(f'Processing : {class_name}/{specific_class}/{severity}')\n",
    "                    \n",
    "                    for file_name in tqdm(os.listdir(severity_dir)):\n",
    "                        file_path = os.path.join(severity_dir, file_name)\n",
    "                        data_pd = pd.read_csv(file_path)\n",
    "                        \n",
    "                        dis_folder = os.path.join(new_mfd_root, class_name)\n",
    "\n",
    "                        specific_class_name = class_name + specific_class.split('_')[0]\n",
    "                        mfd_file_read_save(data_pd, dis_folder, specific_class_name, severity)\n",
    "        \n",
    "        elif class_name == 'normal':\n",
    "            print(f'Processing : {class_name}')\n",
    "            for file_name in tqdm(os.listdir(class_dir)):\n",
    "                file_path = os.path.join(class_dir, file_name)\n",
    "                data_pd = pd.read_csv(file_path)\n",
    "                \n",
    "                \n",
    "                dis_folder = os.path.join(new_mfd_root, class_name)\n",
    "\n",
    "                mfd_file_read_save(data_pd, dis_folder, class_name, 'none')\n",
    "                \n",
    "        else:\n",
    "            print(f'Wrong Class Name : {class_name}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : BearingType_CylindricalRoller/16000/RotatingSpeed_1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [01:11<00:00,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : BearingType_CylindricalRoller/16000/RotatingSpeed_1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [01:13<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : BearingType_CylindricalRoller/16000/RotatingSpeed_600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [01:17<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : BearingType_CylindricalRoller/16000/RotatingSpeed_800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [01:19<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : BearingType_CylindricalRoller/16000/RotatingSpeed_1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [01:21<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : BearingType_CylindricalRoller/16000/RotatingSpeed_1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [01:24<00:00,  2.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : BearingType_CylindricalRoller/8000/RotatingSpeed_1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [01:48<00:00,  3.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : BearingType_CylindricalRoller/8000/RotatingSpeed_1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [01:57<00:00,  3.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : BearingType_CylindricalRoller/8000/RotatingSpeed_600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [02:09<00:00,  4.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : BearingType_CylindricalRoller/8000/RotatingSpeed_800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [02:19<00:00,  4.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : BearingType_CylindricalRoller/8000/RotatingSpeed_1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [02:28<00:00,  4.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : BearingType_CylindricalRoller/8000/RotatingSpeed_1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [02:38<00:00,  4.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : BearingType_TaperedRoller/16000/RotatingSpeed_1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [01:57<00:00,  3.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : BearingType_TaperedRoller/16000/RotatingSpeed_1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [01:59<00:00,  3.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : BearingType_TaperedRoller/16000/RotatingSpeed_600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [02:03<00:00,  3.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : BearingType_TaperedRoller/16000/RotatingSpeed_800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [02:06<00:00,  3.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : BearingType_TaperedRoller/16000/RotatingSpeed_1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [02:08<00:00,  4.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : BearingType_TaperedRoller/16000/RotatingSpeed_1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [02:10<00:00,  4.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : BearingType_TaperedRoller/8000/RotatingSpeed_1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [03:21<00:00,  6.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : BearingType_TaperedRoller/8000/RotatingSpeed_1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [03:32<00:00,  6.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : BearingType_TaperedRoller/8000/RotatingSpeed_600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [03:45<00:00,  7.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : BearingType_TaperedRoller/8000/RotatingSpeed_800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [03:30<00:00,  7.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : BearingType_TaperedRoller/8000/RotatingSpeed_1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [04:05<00:00,  7.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : BearingType_TaperedRoller/8000/RotatingSpeed_1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [04:14<00:00,  7.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : BearingType_DeepGrooveBall/16000/RotatingSpeed_1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [02:45<00:00,  5.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : BearingType_DeepGrooveBall/16000/RotatingSpeed_1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [02:49<00:00,  5.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : BearingType_DeepGrooveBall/16000/RotatingSpeed_600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [02:53<00:00,  5.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : BearingType_DeepGrooveBall/16000/RotatingSpeed_800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [02:54<00:00,  5.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : BearingType_DeepGrooveBall/16000/RotatingSpeed_1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [02:58<00:00,  5.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : BearingType_DeepGrooveBall/16000/RotatingSpeed_1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [03:01<00:00,  5.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : BearingType_DeepGrooveBall/8000/RotatingSpeed_1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [05:00<00:00,  9.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : BearingType_DeepGrooveBall/8000/RotatingSpeed_1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [05:12<00:00,  9.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : BearingType_DeepGrooveBall/8000/RotatingSpeed_600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [05:24<00:00, 10.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : BearingType_DeepGrooveBall/8000/RotatingSpeed_800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [05:35<00:00, 10.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : BearingType_DeepGrooveBall/8000/RotatingSpeed_1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [05:45<00:00, 10.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : BearingType_DeepGrooveBall/8000/RotatingSpeed_1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [05:56<00:00, 11.14s/it]\n"
     ]
    }
   ],
   "source": [
    "def snu(data_root, new_data_root):\n",
    "\n",
    "    snu_root = os.path.join(data_root, '5_SNU')\n",
    "\n",
    "    window_size = 1.0\n",
    "    stride = 0.5\n",
    "\n",
    "    rotary_class_dict = {'H' : 'normal', \n",
    "                        'L' : 'losseness', \n",
    "                        'U1' : 'unbalance',    # 2g\n",
    "                        'U2' : 'unbalance',    # 3g\n",
    "                        'U3' : 'unbalance',    # 5g\n",
    "                        'M1' : 'misalignment', # 0.6mm\n",
    "                        'M2' : 'misalignment', # 0.8mm\n",
    "                        'M3' : 'misalignment'  # 1.0mm\n",
    "                        }\n",
    "    bearing_class_dict = {'H' : 'normal', \n",
    "                        'B' : 'encompass', \n",
    "                        'IR': 'bpfi', \n",
    "                        'OR': 'bpfo'}\n",
    "    unbalance_severity_list = ['2g', '3g', '5g']\n",
    "    misalignment_severity_list = ['0.6mm', '0.8mm', '1mm']\n",
    "    load_condition = 'unknown'\n",
    "\n",
    "    new_snu_root = os.path.join(new_data_root, 'snu')\n",
    "    if os.path.isdir(new_snu_root):\n",
    "        shutil.rmtree(new_snu_root)\n",
    "    os.mkdir(new_snu_root)\n",
    "\n",
    "    for bearing_type in os.listdir(snu_root):\n",
    "        bearing_dir = os.path.join(snu_root, bearing_type)\n",
    "        \n",
    "        for sampling_rate in os.listdir(bearing_dir):\n",
    "            sampling_rate_dir = os.path.join(bearing_dir, sampling_rate)\n",
    "            sampling_rate_str = f'{int(sampling_rate.split(\"_\")[-1])/1000}kHz'\n",
    "            sampling_rate = int(sampling_rate.split('_')[-1])\n",
    "            \n",
    "            for speed in os.listdir(sampling_rate_dir):\n",
    "                speed_dir = os.path.join(sampling_rate_dir, speed)\n",
    "                rpm = speed.split('_')[-1]\n",
    "                \n",
    "                print(f'Processing : {bearing_type}/{sampling_rate}/{speed}')\n",
    "                for file_name in tqdm(os.listdir(speed_dir)):\n",
    "                    file_path = os.path.join(speed_dir, file_name)\n",
    "                    mat_file = io.loadmat(file_path)\n",
    "                    disk_y = mat_file['Data']\n",
    "                    \n",
    "                    rotary_class_query = file_name.split('_')[0]\n",
    "                    rotary_class = rotary_class_dict[rotary_class_query]\n",
    "                    if rotary_class == 'unbalance':\n",
    "                        severity = unbalance_severity_list[int(rotary_class_query[-1])-1]\n",
    "                    elif rotary_class == 'misalignment':\n",
    "                        severity = misalignment_severity_list[int(rotary_class_query[-1])-1]\n",
    "                    else:\n",
    "                        severity = 'none'\n",
    "                    bearing_class_query = file_name.split('_')[1]\n",
    "                    bearing_class = bearing_class_dict[bearing_class_query]\n",
    "                    \n",
    "                    class_name = rotary_class\n",
    "                    folder_dist = os.path.join(new_snu_root, class_name)\n",
    "                    if not os.path.exists(folder_dist):\n",
    "                        os.mkdir(folder_dist)\n",
    "                        \n",
    "                    # Slice data_pd by 1-second window with 0.5-second stride\n",
    "                    window_samples = int(window_size * sampling_rate)\n",
    "                    stride_samples = int(stride * sampling_rate)\n",
    "                    num_rows = len(disk_y)\n",
    "\n",
    "                    for slice_start in range(0, num_rows - window_samples + 1, stride_samples):\n",
    "                        slice_end = slice_start + window_samples\n",
    "                        sliced_data = disk_y[slice_start:slice_end]\n",
    "                        \n",
    "                        # Save sliced data to a CSV file\n",
    "                        output_file = os.path.join(folder_dist, f'{rotary_class}+{bearing_class}_{sampling_rate_str}_{rpm}_{severity}_{load_condition}_{len(os.listdir(folder_dist))+1}.csv')\n",
    "                        data_pd = pd.DataFrame(sliced_data, columns=['disk_y'])\n",
    "                        \n",
    "                        data_pd.to_csv(output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
